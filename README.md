# Tourist Trip Design Problem (TTDP) con Graph Embeddings y Graph Neural Networks

Este repositorio contiene el desarrollo de mi trabajo de grado de MaestrÃ­a en Inteligencia Artificial, enfocado en resolver el **Tourist Trip Design Problem (TTDP)** con un enfoque innovador apoyado en Inteligencia Artificial, especÃ­ficamente en **Graph Embeddings** y **Graph Neural Networks (GNNs)**.

## DescripciÃ³n del Problema

El **Tourist Trip Design Problem (TTDP)** es un problema de optimizaciÃ³n combinatoria que busca diseÃ±ar itinerarios turÃ­sticos Ã³ptimos considerando:

- **Puntos de InterÃ©s (POIs)**: Cada uno con coordenadas (x,y), tiempo de servicio, beneficio y ventanas de tiempo
- **Restricciones**: Ventanas de tiempo (open/close), tiempo de servicio, tiempo de viaje entre POIs
- **Objetivo**: Maximizar el beneficio total visitando la mayor cantidad de POIs factibles

## Enfoque Innovador: IA + Grafos

### **VisiÃ³n General**
El proyecto busca llevar el TTDP mÃ¡s allÃ¡ de las heurÃ­sticas clÃ¡sicas, explorando si los **embeddings de grafos** y **modelos de grafos** pueden:

- **Representar mejor** las relaciones entre POIs
- **Mejorar la calidad** de las rutas (mÃ¡s beneficios en menos tiempo)
- **Facilitar la personalizaciÃ³n** futura (adaptar a perfiles de usuarios)

### **Flujo de la Propuesta**

#### **1. Baseline Tradicional**
- **HeurÃ­stica/MetaheurÃ­stica**: Greedy / GRASP-VND que respete todas las restricciones
- **PropÃ³sito**: Punto de comparaciÃ³n para evaluar mejoras del enfoque de IA

#### **2. Graph Embeddings**
- **TÃ©cnica**: Node2Vec / DeepWalk sobre grafo construido con distancias y tiempos
- **Beneficio**: Captura relaciones mÃ¡s ricas que distancias puras:
  - Afinidad latente entre nodos
  - Roles estructurales
  - Comunidades naturales

#### **3. IntegraciÃ³n de Embeddings en el Planificador**
- **Utilidad HÃ­brida**: Similitud latente + beneficio - costo (tiempo)
- **OptimizaciÃ³n**: Combinar embeddings como seÃ±al de similitud en construcciÃ³n de rutas
- **Eficiencia**: Pruning por k-NN latente para reducir complejidad

#### **4. Embeddings SemÃ¡nticos/HeterogÃ©neos**
- **Enriquecimiento**: CategorÃ­as de POI, zonas geogrÃ¡ficas, preferencias
- **Resultado**: Embeddings mÃ¡s expresivos y contextuales

#### **5. Learning-to-Rank para Transiciones** 
- **Modelo**: MLP pequeÃ±o que aprende a puntuar transiciones uâ†’v
- **Features**: Embeddings + distancia + compatibilidad de ventanas de tiempo
- **Objetivo**: Reforzar elecciÃ³n de rutas mÃ¡s prometedoras

#### **6. ExtensiÃ³n a Graph Neural Networks** 
- **Arquitectura**: GCN o GraphSAGE ligera para refinar embeddings
- **InclusiÃ³n**: Atributos de nodos y aristas
- **Potencial**: Salto hacia enfoque mÃ¡s profundo de IA

#### **7. ValidaciÃ³n Experimental** 
- **ComparaciÃ³n**: Baseline vs. variantes con embeddings, semÃ¡ntica, link scorer, GNN
- **MÃ©tricas**: Score total, POIs visitados, factibilidad, tiempo de cÃ³mputo, estabilidad
- **AnÃ¡lisis**: Ablations para entender impacto de cada componente

#### **8. ConsolidaciÃ³n** 
- **Sistema**: Pipeline reproducible (one-click)
- **DocumentaciÃ³n**: MetodologÃ­a, resultados y discusiÃ³n
- **Futuro**: Limitaciones y lÃ­neas futuras (RL, datos reales, GNN temporales)

## Estructura del Repositorio

```
ttdp-trabajo-grado/
â”œâ”€â”€ exact_pulp.py              # Solver exacto MILP (PuLP + CBC) - Referencia
â”œâ”€â”€ baseline_greedy.py         # Algoritmo greedy de lÃ­nea base
â”œâ”€â”€ baseline_grasp_vnd.py      # MetaheurÃ­stica GRASP-VND (baseline)
â”œâ”€â”€ graph_embeddings/          # ImplementaciÃ³n de embeddings de grafos
â”‚   â”œâ”€â”€ node2vec_ttdp.py      # Node2Vec para POIs
â”‚   â”œâ”€â”€ deepwalk_ttdp.py      # DeepWalk para POIs
â”‚   â””â”€â”€ graph_builder.py      # ConstrucciÃ³n del grafo POI
â”œâ”€â”€ neural_approaches/         # Enfoques de IA
â”‚   â”œâ”€â”€ learning_to_rank.py   # MLP para scoring de transiciones
â”‚   â”œâ”€â”€ gnn_ttdp.py          # Graph Neural Networks
â”‚   â””â”€â”€ hybrid_planner.py     # Planificador hÃ­brido (embeddings + heurÃ­stica)
â”œâ”€â”€ data/                      # Instancias de prueba
â”‚   â”œâ”€â”€ synthetic/            # 20 instancias hptoptw-j** (11,16,21 nodos)
â”‚   â””â”€â”€ real/                 # 6 benchmarks TOPTW de la literatura
â”œâ”€â”€ experiments/               # Resultados experimentales
â”‚   â”œâ”€â”€ configs/              # Configuraciones de experimentos
â”‚   â”œâ”€â”€ logs/                 # Logs de ejecuciÃ³n
â”‚   â”œâ”€â”€ tables/               # Tablas de resultados
â”‚   â””â”€â”€ figures/              # GrÃ¡ficos y visualizaciones
â”œâ”€â”€ notebooks/                 # AnÃ¡lisis y experimentos
â”‚   â”œâ”€â”€ eda/                  # AnÃ¡lisis exploratorio de datos
â”‚   â”œâ”€â”€ embeddings_analysis/  # AnÃ¡lisis de embeddings generados
â”‚   â”œâ”€â”€ experiments/          # Experimentos comparativos
â”‚   â””â”€â”€ ablation_study/       # Estudio de ablaciÃ³n de componentes
â””â”€â”€ references/               # BibliografÃ­a y papers
```

## InstalaciÃ³n y Uso

### Requisitos
```bash
pip install pulp pandas numpy networkx node2vec torch torch-geometric scikit-learn matplotlib seaborn
```

### EjecuciÃ³n del Baseline
```bash
# Algoritmo greedy
python baseline_greedy.py --file data/synthetic/hptoptw-j11a.csv --name hptoptw-j11a --runs 3

# MetaheurÃ­stica GRASP-VND
python baseline_grasp_vnd.py --file data/synthetic/hptoptw-j11a.csv --name hptoptw-j11a
```

### GeneraciÃ³n de Embeddings
```bash
# Node2Vec embeddings
python graph_embeddings/node2vec_ttdp.py --file data/synthetic/hptoptw-j11a.csv --dimensions 64

# DeepWalk embeddings
python graph_embeddings/deepwalk_ttdp.py --file data/synthetic/hptoptw-j11a.csv --dimensions 64
```

### Planificador HÃ­brido
```bash
# Planificador con embeddings
python neural_approaches/hybrid_planner.py --file data/synthetic/hptoptw-j11a.csv --embeddings node2vec --alpha 0.7
```

##  Formato de Datos

### Instancias SintÃ©ticas (CSV)
```csv
id,x,y,s,p,a,b,f,instance,k,i,u,l
0,53,46,0,0,1,700,0.8,hptoptw-j11a,2,11,5,3
1,43,32,90,20,29,101,0.7,hptoptw-j11a,2,11,5,3
...
```

**Columnas**:
- `id`: Identificador del POI (0 = depÃ³sito)
- `x,y`: Coordenadas cartesianas
- `s`: Tiempo de servicio
- `p`: Beneficio/Profit
- `a`: Apertura de ventana de tiempo
- `b`: Cierre de ventana de tiempo
- `f`: Factor de importancia (opcional)

## MetodologÃ­a de IA

### **1. ConstrucciÃ³n del Grafo POI**
- **Nodos**: POIs con atributos (coordenadas, beneficios, ventanas de tiempo)
- **Aristas**: Conexiones basadas en distancias y compatibilidad temporal
- **Pesos**: CombinaciÃ³n de distancia euclidiana y restricciones de tiempo

### **2. Graph Embeddings**
- **Node2Vec**: Random walks con parÃ¡metros p,q para capturar roles estructurales
- **DeepWalk**: Random walks uniformes para representaciones latentes
- **DimensiÃ³n**: 64-128 vectores por POI

### **3. Learning-to-Rank**
- **Features de entrada**: 
  - Embeddings de POIs origen y destino
  - Distancia euclidiana
  - Compatibilidad de ventanas de tiempo
  - Tiempo de servicio
- **Salida**: Score de transiciÃ³n (0-1)
- **Entrenamiento**: Datos sintÃ©ticos generados por baseline

### **4. Graph Neural Networks**
- **Arquitectura**: GraphSAGE o GCN ligera
- **Capas**: 2-3 capas convolucionales
- **Pooling**: Global mean pooling para embeddings finales
- **Fine-tuning**: Ajuste de embeddings para tarea especÃ­fica

### **5. Planificador HÃ­brido**
- **CombinaciÃ³n**: Utilidad tradicional + score de embeddings
- **ParÃ¡metro Î±**: Balance entre heurÃ­stica clÃ¡sica y similitud latente
- **Pruning**: k-NN en espacio de embeddings para reducir complejidad

##  MÃ©tricas de EvaluaciÃ³n

### **Calidad de SoluciÃ³n**
- **Score total**: Beneficio acumulado de la ruta
- **POIs visitados**: NÃºmero de puntos incluidos
- **Factibilidad**: Cumplimiento de todas las restricciones

### **Eficiencia Computacional**
- **Tiempo de cÃ³mputo**: Tiempo total de ejecuciÃ³n
- **Escalabilidad**: Comportamiento con instancias mÃ¡s grandes
- **Estabilidad**: Consistencia entre ejecuciones

### **AnÃ¡lisis de Embeddings**
- **Calidad de representaciÃ³n**: T-SNE visualizations
- **Similitud semÃ¡ntica**: CorrelaciÃ³n con caracterÃ­sticas de POIs
- **Transfer learning**: Aplicabilidad a nuevas instancias

## PrÃ³ximos Pasos

### **Fase 1: Baseline y Embeddings** (En progreso)
1. âœ… Implementar baseline greedy y GRASP-VND
2. ğŸ”„ Generar embeddings con Node2Vec/DeepWalk
3. ğŸ”„ AnÃ¡lisis exploratorio de embeddings

### **Fase 2: IntegraciÃ³n y Learning-to-Rank**
1. ğŸ”„ Planificador hÃ­brido con embeddings
2. ğŸ”„ MLP para scoring de transiciones
3. ğŸ”„ ValidaciÃ³n experimental inicial

### **Fase 3: GNNs y OptimizaciÃ³n**
1. ğŸ”„ ImplementaciÃ³n de GraphSAGE/GCN
2. ğŸ”„ Fine-tuning de embeddings
3. ğŸ”„ OptimizaciÃ³n de hiperparÃ¡metros

### **Fase 4: ValidaciÃ³n y ConsolidaciÃ³n**
1. ğŸ”„ Estudio de ablaciÃ³n completo
2. ğŸ”„ ComparaciÃ³n con mÃ©todos del estado del arte
3. ğŸ”„ Pipeline reproducible y documentaciÃ³n

## ğŸ“š Referencias

### **TTDP y OptimizaciÃ³n**
- **TTDP-Small**: [Instancias oficiales](https://jrmontoya.wordpress.com/research/instances/ttdp-small/)
- **TOPTW Benchmarks**: Conjunto de instancias reales de la literatura

### **Graph Embeddings y GNNs**
- **Node2Vec**: Grover, A., & Leskovec, J. (2016). Node2vec: Scalable feature learning for networks
- **DeepWalk**: Perozzi, B., et al. (2014). Deepwalk: Online learning of social representations
- **GraphSAGE**: Hamilton, W., et al. (2017). Inductive representation learning on large graphs
- **GCN**: Kipf, T. N., & Welling, M. (2017). Semi-supervised classification with graph convolutional networks

### **Learning-to-Rank y Aplicaciones**
- **LTR en Grafos**: Aplicaciones de ranking en problemas de optimizaciÃ³n combinatoria
- **HÃ­bridos IA + HeurÃ­sticas**: CombinaciÃ³n de mÃ©todos clÃ¡sicos y modernos

##  ContribuciÃ³n

Este es un proyecto acadÃ©mico de trabajo de grado. Para contribuciones o consultas, contactar al autor.

##  Licencia

Proyecto acadÃ©mico - Universidad Javeriana. Los algoritmos externos mantienen sus respectivas licencias originales.

---

**Desarrollado por**: Juan SebastiÃ¡n Navas GÃ³mez 
**InstituciÃ³n**: Pontificia Universidad Javeriana  
**Programa**: MaestrÃ­a en Inteligencia Artificial  
**AÃ±o**: 2025  
**Enfoque**: Graph Embeddings + Graph Neural Networks para TTDP

### Notas de ejecuciÃ³n (Actualizado)
- Exacto multiâ€‘ruta k (src):
  - CSV con k en el archivo: `python ttdp-trabajo-grado/src/exact_pulp_k_routes.py --file ttdp-trabajo-grado/data/synthetic/hptoptw-j11a.csv --name hptoptw-j11a --time-limit 60`
  - Forzar k por CLI: `python ttdp-trabajo-grado/src/exact_pulp_k_routes.py --file ttdp-trabajo-grado/data/synthetic/hptoptw-j11a.csv --name hptoptw-j11a --k 2 --time-limit 60`
- Requisitos para exacto k: `pulp`, ademÃ¡s de `numpy` y `pandas` (y `openpyxl` si usas Excel en otros scripts).
